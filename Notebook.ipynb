{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856b8e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"lv-comments-2019_main.csv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f123f53e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "label=LabelEncoder()\n",
    "df['polarity']=label.fit_transform(df['polarity'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c82073a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfx = pd.read_csv(\"lv-comments-2019_main.csv\", sep='\\t')\n",
    "#calculate, assign new columns\n",
    "dfx['Characters'] = df['content'].str.len()\n",
    "dfx['Words'] = df['content'].str.split().str.len()\n",
    "#export to CSV\n",
    "df.to_csv('out.csv', index=False)\n",
    "#print values\n",
    "mean_characters = dfx['Characters'].mean()\n",
    "mean_words = dfx['Words'].mean()\n",
    "print(mean_characters)\n",
    "print(mean_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0485a00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.countplot('polarity',data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac2af9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwordsfile = open('data/stopwords-lv.txt', mode='r', encoding='utf-8')\n",
    "stopwords_lv = stopwordsfile.read()\n",
    "stopwordsfile.close()\n",
    "stopwords_lv = stopwords_lv[1:].split('\\n')\n",
    "\n",
    "!pip install LatvianStemmer\n",
    "import LatvianStemmer\n",
    "\n",
    "import gzip\n",
    "import re\n",
    "dictionary_file = gzip.open('data/lemmatization_dictionary_lv.dat.gz', 'rt', encoding='utf-8')\n",
    "lemmatization_dictionary = {}\n",
    "for line in dictionary_file:\n",
    "    values = line.split('\\t')\n",
    "    lemmatization_dictionary[values[0]] = values[1][:-1]\n",
    "dictionary_file.close()\n",
    "\n",
    "def lemmatize_lv(word):\n",
    "    if word in lemmatization_dictionary:\n",
    "        return lemmatization_dictionary[word]\n",
    "    else:\n",
    "        return word\n",
    "    \n",
    "def process_message(review_text):\n",
    "    new_review_text = re.sub(r'@[^ ]+', '', review_text)\n",
    "    new_review_text = re.sub(\"http[^\\s]+\", '', new_review_text)\n",
    "    new_review_text = re.sub(r'[^\\w\\s]', ' ', new_review_text)\n",
    "    new_review_text = re.sub('_', ' ', new_review_text)\n",
    "    new_review_text = re.sub('[0-9]+', '', new_review_text)\n",
    "    words = new_review_text.lower().split()\n",
    "    words = [w for w in words if not w in stopwords_lv]\n",
    "    #lemmatizer\n",
    "    words = [lemmatize_lv(word) for word in words]\n",
    "    # stemmer\n",
    "    #words = [LatvianStemmer.stem(word) for word in words]\n",
    "    return (\" \".join(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5127ed6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['content']=df['content'].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a5e372",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_content']=df['content'].apply(lambda x: process_message(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225143ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_content']=df['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02ccab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.clean_content.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f5106f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6008359f",
   "metadata": {},
   "outputs": [],
   "source": [
    " pd.options.display.max_colwidth = 900  # set a value as your need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afeec96",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08191633",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bdbbe40",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62735b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "from wordcloud import WordCloud,STOPWORDS\n",
    "def createWrdCloudForSentiment(sentiment):\n",
    "    sentiment_num = 1 if sentiment== 'Hate' else 0\n",
    "    temp_df = df[df.polarity==sentiment_num]\n",
    "    words = \" \".join(temp_df.clean_content)\n",
    "    cleaned_words = \" \".join([w for w in words.split()\n",
    "                                  if 'http' not in w\n",
    "                                    and not w.startswith('@')\n",
    "                                    and w!='RT'])\n",
    "\n",
    "    wrdcld = WordCloud(stopwords=STOPWORDS,\n",
    "                      background_color='black',\n",
    "                      width=1500,\n",
    "                      height=1000).generate(cleaned_words)\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.imshow(wrdcld)\n",
    "    plt.axis('off')\n",
    "    plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122e1a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "createWrdCloudForSentiment('Hate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e40c1f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "createWrdCloudForSentiment('Positive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571156cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df, testing_df =  train_test_split(df, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1050d6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, HashingVectorizer\n",
    "#vectorizer = TfidfVectorizer()\n",
    "#train_tfidf_model = vectorizer.fit_transform(df.clean_content)\n",
    "#test_tfidf_model = vectorizer.transform(testing_df.clean_content)\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "train_tfidf_model = vectorizer.fit_transform(df.clean_content)\n",
    "test_tfidf_model = vectorizer.transform(testing_df.clean_content)\n",
    "\n",
    "#vectorizer = HashingVectorizer()\n",
    "#train_tfidf_model = vectorizer.fit_transform(df.clean_content)\n",
    "#test_tfidf_model = vectorizer.transform(testing_df.clean_content)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58b8f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tfidf_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eecfa0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tfidf = pd.DataFrame(train_tfidf_model)\n",
    "train_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343ade33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "\n",
    "cls = [LogisticRegression(),\n",
    "       MultinomialNB(),\n",
    "       BernoulliNB(),\n",
    "       DecisionTreeClassifier(),\n",
    "       RandomForestClassifier(n_estimators=200),\n",
    "       KNeighborsClassifier(n_neighbors = 5),\n",
    "       SVC(),\n",
    "       LinearSVC(),\n",
    "       XGBClassifier(),\n",
    "       SGDClassifier(),\n",
    "       AdaBoostClassifier(),\n",
    "       MLPClassifier(),\n",
    "       BaggingClassifier()]\n",
    "\n",
    "cls_name = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e637d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tfidf_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fafa8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.polarity.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d9cdd0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "lbl_actual = testing_df.polarity\n",
    "i = 0\n",
    "accuracy = []\n",
    "for cl in cls:\n",
    "    model = cl.fit(train_tfidf_model,df.polarity)\n",
    "    lbl_pred = model.predict(test_tfidf_model)\n",
    "    a = (100*accuracy_score(lbl_pred, lbl_actual))\n",
    "    a = round(a,2)\n",
    "    accuracy.append(a)\n",
    "    cls_name.append(cl.__class__.__name__)\n",
    "    print (\"{}  Accuracy Score : {}%\".format(cls_name[i],a))\n",
    "    print ( classification_report(lbl_pred, lbl_actual))\n",
    "    i +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52376b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(cls_name, accuracy)\n",
    "plt.xticks(rotation=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baea9cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict accuracy\n",
    "def getModelAccuracy_LogicalReg(model_name, sampled_train_df) :\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    sampled_train_tfidf_model = vectorizer.fit_transform(sampled_train_df.clean_content)\n",
    "    sampled_test_tfidf_model = vectorizer.transform(testing_df.clean_content)\n",
    "\n",
    "    #Prediction\n",
    "    sample_model = LogisticRegression().fit(sampled_train_tfidf_model,sampled_train_df.polarity)\n",
    "    lg_lbl_pred = sample_model.predict(sampled_test_tfidf_model)\n",
    "    a = (100*accuracy_score(lg_lbl_pred, lbl_actual))\n",
    "    a = round(a,2)\n",
    "    print (\"{}  Accuracy Score : {}%\".format(model_name,a))\n",
    "    #print(type(a))\n",
    "    return float(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad37629",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getModelAccuracy_RFC(model_name, sampled_train_df) :\n",
    "\n",
    "    \n",
    "    vectorizer = TfidfVectorizer()\n",
    "    sampled_train_tfidf_model = vectorizer.fit_transform(sampled_train_df.clean_content)\n",
    "    sampled_test_tfidf_model = vectorizer.transform(testing_df.clean_content)\n",
    "\n",
    "    sample_model = RandomForestClassifier(n_estimators=200).fit(sampled_train_tfidf_model,sampled_train_df.polarity)\n",
    "    lg_lbl_pred = sample_model.predict(sampled_test_tfidf_model)\n",
    "    a = (100*accuracy_score(lg_lbl_pred, lbl_actual))\n",
    "    a = round(a,2)\n",
    "    print (\"{}  Accuracy Score : {}%\".format(model_name,a))\n",
    "    return float(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4fe81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_accuracy = []\n",
    "rfc_accuracy = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35b9e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = getModelAccuracy_LogicalReg(\"Train dataset\", df)\n",
    "\n",
    "log_accuracy.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5998c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aace04f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = getModelAccuracy_RFC(\"Train dataset\", df)\n",
    "rfc_accuracy.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6145095c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1472f504",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createPieChartFor(t_df):\n",
    "    Lst = 100*t_df.value_counts()/len(t_df)\n",
    "    \n",
    "    # set data for pie chart\n",
    "    labels = t_df.value_counts().index.values\n",
    "    sizes =  Lst \n",
    "    \n",
    "    # set labels\n",
    "    fig1, ax1 = plt.subplots()\n",
    "    ax1.pie(sizes, labels=labels, autopct='%1.2f%%', shadow=True, startangle=90)\n",
    "    ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd4b65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "createPieChartFor(df.polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b198c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install Flask-JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf75997",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb466d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import csv\n",
    "import datetime\n",
    "import dateutil.parser\n",
    "import unicodedata\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b741a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "MY_BEARER_TOKEN = \"that is secret\"\n",
    "client = tweepy.Client(bearer_token=MY_BEARER_TOKEN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a7d1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"gobzems lang:lv\"\n",
    "start_time = \"2022-03-22T00:00:00Z\"\n",
    "end_time = \"2022-03-28T12:00:00Z\"\n",
    "\n",
    "tweets = client.search_recent_tweets(query=query,\n",
    "                                     start_time=start_time,\n",
    "                                     end_time=end_time,\n",
    "                                     tweet_fields = [\"created_at\", \"text\", \"source\"],\n",
    "                                     user_fields = [\"name\", \"username\", \"location\", \"verified\", \"description\"],\n",
    "                                     max_results = 100,\n",
    "                                     expansions='author_id'\n",
    "                                     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d79d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(tweets.data))\n",
    "print(len(tweets.includes[\"users\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ea6cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_tweet = tweets.data[0]\n",
    "dict(first_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528e44a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "tweet_info_ls = []\n",
    "for tweet, user in zip(tweets.data, tweets.includes['users']):\n",
    "    tweet_info = {\n",
    "        'created_at': tweet.created_at,\n",
    "        'text': tweet.text,\n",
    "        'source': tweet.source,\n",
    "        'name': user.name,\n",
    "        'username': user.username,\n",
    "        'location': user.location,\n",
    "        'verified': user.verified,\n",
    "        'description': user.description\n",
    "    }\n",
    "    tweet_info_ls.append(tweet_info)\n",
    "tweets_df = pd.DataFrame(tweet_info_ls)\n",
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90aa9775",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df.to_csv('gobzems.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba05e06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df.drop(columns=['created_at', 'source', \"name\", \"username\", \"location\", \"verified\", \"description\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e12417",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df['text']=tweets_df['text'].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7060f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df['clean_text']=tweets_df['text'].apply(lambda x: process_message(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccd3d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df.clean_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd5f8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_train_tfidf_model = vectorizer.fit_transform(df.clean_content)\n",
    "sampled_test_tfidf_model = vectorizer.transform(tweets_df.clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d70c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_model = BaggingClassifier().fit(sampled_train_tfidf_model,df.polarity)\n",
    "lg_lbl_pred = sample_model.predict(sampled_test_tfidf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763c3d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "lg_lbl_pred_df = pd.DataFrame({'tweet_cleaned' : tweets_df.clean_text,\n",
    "                            'tweet' : tweets_df.text,\n",
    "                            'polarity' : lg_lbl_pred})\n",
    "lg_lbl_pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87735e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lg_lbl_pred_df.polarity.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4dbc0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "lg_lbl_pred_df.to_csv('gobzems-output.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
